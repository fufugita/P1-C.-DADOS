{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Guilherme Fugita\n",
    "\n",
    "Nome: Paola Friedel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aten√ß√£o: Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import re \n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[:;\\n\"'']' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esperamos trabalhar no diret√≥rio\n",
      "C:\\Users\\Usu√°rio\\Desktop\\C dados\n"
     ]
    }
   ],
   "source": [
    "print('Esperamos trabalhar no diret√≥rio')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Big Mac.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>queria tnt comer um big mac üò´</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doida pra comer um big mac, daq a pouco vou am...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vou assistir miss americana dnv enquanto almo√ß...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qria um big mac agr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@juhrangel_ voltou n√£o, um passarinho me conto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Relev√¢ncia\n",
       "0                      queria tnt comer um big mac üò´           1\n",
       "1  doida pra comer um big mac, daq a pouco vou am...           1\n",
       "2  vou assistir miss americana dnv enquanto almo√ß...           1\n",
       "3                                qria um big mac agr           1\n",
       "4  @juhrangel_ voltou n√£o, um passarinho me conto...           1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Relev√¢ncia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>queria tnt comer um big mac üò´</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doida pra comer um big mac, daq a pouco vou am...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vou assistir miss americana dnv enquanto almo√ß...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qria um big mac agr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@juhrangel_ voltou n√£o, um passarinho me conto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Relev√¢ncia\n",
       "0                      queria tnt comer um big mac üò´           1\n",
       "1  doida pra comer um big mac, daq a pouco vou am...           1\n",
       "2  vou assistir miss americana dnv enquanto almo√ß...           1\n",
       "3                                qria um big mac agr           1\n",
       "4  @juhrangel_ voltou n√£o, um passarinho me conto...           1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Escolhemos o produto do McDonalds, o lanche BigMac, tudo que √© considerado relevante agrega valores positivos e negativos para o produto como uma critica tanto quanto o desejo dos usu√°rios em rela√ß√£o ao produto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'txts/tudo.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-0ecaac526a70>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#--------TUDO--------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'txts/tudo.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtodos_tweets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtweetTr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Treinamento\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtweetTrC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcleanup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweetTr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'txts/tudo.txt'"
     ]
    }
   ],
   "source": [
    "#--------TUDO--------\n",
    "with open('txts/tudo.txt', 'w', encoding=\"utf-8\") as todos_tweets:\n",
    "    for j in range(len(train)):\n",
    "        tweetTr = train.loc[j,\"Treinamento\"]\n",
    "        tweetTrC = cleanup(tweetTr)\n",
    "        todos_tweets.write(\"{0} \".format(tweetTrC))\n",
    "        \n",
    "#--------RELEVANTES--------\n",
    "Rel = train.loc[train['Relev√¢ncia'] == 1, ['Treinamento']]\n",
    "\n",
    "with open('txts/relevantes.txt', 'w', encoding=\"utf-8\") as tweets_relevantes:\n",
    "    for q in range(len(Rel)):\n",
    "        RelTr = Rel.iloc[q, 0]\n",
    "        RelTrC = cleanup(RelTr)\n",
    "        tweets_relevantes.write(\"{0} \".format(RelTrC))\n",
    "\n",
    "#--------TRRELEVANTES--------\n",
    "IRel = train.loc[train['Relev√¢ncia'] == 0, ['Treinamento']]\n",
    "with open('txts/irrelevantes.txt', 'w', encoding=\"utf-8\") as tweets_irrelevantes:\n",
    "    for q in range(len(IRel)):\n",
    "        IRelTr = IRel.iloc[q, 0]\n",
    "        IRelTrC = cleanup(IRelTr)\n",
    "        tweets_irrelevantes.write(\"{0} \".format(IRelTrC))\n",
    "    \n",
    "#--------LENDO OS ARQUIVOS--------   \n",
    "with open(\"txts/tudo.txt\", \"r\", encoding=\"utf-8\") as arquivo_texto:\n",
    "    tudo_raw = arquivo_texto.read()  \n",
    "    \n",
    "with open(\"txts/relevantes.txt\", \"r\", encoding=\"utf-8\") as arquivo_texto:\n",
    "    relevantes_raw = arquivo_texto.read() \n",
    "    relevantes = relevantes_raw\n",
    "with open(\"txts/irrelevantes.txt\", \"r\", encoding=\"utf-8\") as arquivo_texto:\n",
    "    irrelevantes_raw = arquivo_texto.read() \n",
    "    irrelevantes = irrelevantes_raw\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#--------RELEVANTES--------\n",
    "todas_palavras_relevantes = relevantes_raw.split()\n",
    "serie_relevantes = pd.Series(todas_palavras_relevantes)\n",
    "tabela_relevantes = serie_relevantes.value_counts()\n",
    "tabela_relevantes_relativa = serie_relevantes.value_counts(True)\n",
    "\n",
    "#--------TRRELEVANTES--------\n",
    "todas_palavras_irrelevantes = irrelevantes_raw.split()\n",
    "serie_irrelevantes = pd.Series(todas_palavras_irrelevantes)\n",
    "tabela_irrelevantes = serie_irrelevantes.value_counts()\n",
    "tabela_irrelevantes_relativa = serie_irrelevantes.value_counts(True)\n",
    "\n",
    "#--------TUDO--------\n",
    "tudo = relevantes + irrelevantes\n",
    "todas_palavras = tudo.split()\n",
    "serie_tudo = pd.Series(todas_palavras)\n",
    "tabela_tudo_relativa = serie_tudo.value_counts(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probR = len(todas_palavras_relevantes) / len(todas_palavras)\n",
    "probI = len(todas_palavras_irrelevantes) / len(todas_palavras)\n",
    "\n",
    "print(round(probR,5))\n",
    "print(round(probI,5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------TESTE--------\n",
    "classificadores = []\n",
    "classificador = [] #para a compara√ß√£o final\n",
    "tweets =[]\n",
    "for j in range(len(test)):\n",
    "    tweetTeste = test.loc[j, \"Teste\"]\n",
    "    tweetTeste = cleanup(tweetTeste)\n",
    "    tweets.append(tweetTeste)\n",
    "    classificadores.append(tweets)\n",
    "    classificador.append(tweetTeste)\n",
    "    tweets = []\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores = []\n",
    "for h in range(len(classificadores)):\n",
    "    g = classificadores[h]\n",
    "    for tweet in g:\n",
    "        palavrasR = []\n",
    "        for i in tweet.split():\n",
    "            if i not in tabela_relevantes:\n",
    "                pr = 0\n",
    "                pR = (pr + 1) / (len(relevantes) + len(tudo))\n",
    "                palavrasR.append(pR)\n",
    "                probTweetDadoR = np.prod(palavrasR)\n",
    "            else: \n",
    "                pr = tabela_relevantes[i]\n",
    "                pR = (pr + 1) / (len(relevantes) + len(tudo))\n",
    "                palavrasR.append(pR)\n",
    "                probTweetDadoR = np.prod(palavrasR)\n",
    "            \n",
    "        palavrasI = []\n",
    "        for j in tweet.split():\n",
    "            if i not in tabela_irrelevantes:\n",
    "                pi1 = 0\n",
    "                pI = (pi1 + 1) / (len(irrelevantes) + len(tudo))\n",
    "                palavrasI.append(pI)\n",
    "                probTweetDadoI = np.prod(palavrasI)\n",
    "            else: \n",
    "                pii = tabela_irrelevantes[i]\n",
    "                pI = (pi1 + 1) / (len(irrelevantes) + len(tudo))\n",
    "                palavrasR.append(pI)\n",
    "                probTweetDadoI = np.prod(palavrasI)\n",
    "            \n",
    "        probRTweet = probTweetDadoR * probR\n",
    "        probITweet = probTweetDadoI * probI\n",
    "        if probRTweet > probITweet:\n",
    "            valores.append(\"Relevante\")\n",
    "        else:\n",
    "            valores.append(\"Irrelevante\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(valores)):\n",
    "    test.loc[i, \"Comparador\"] = valores[i]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------VERDADEIRO POSITIVO--------\n",
    "rel1x = test.loc[(test['Relev√¢ncia'] == 1)]\n",
    "VP = rel1x.loc[(rel1x['Comparador'] == 'Relevante')]\n",
    "\n",
    "#--------FALSO POSITIVO--------\n",
    "rel0x = test.loc[(test['Relev√¢ncia'] == 0)]\n",
    "FP = rel0x.loc[(rel0x['Comparador'] == 'Relevante')]\n",
    "\n",
    "#--------VERDADEIRO NEGATIVO--------\n",
    "rel0y = test.loc[(test['Relev√¢ncia'] == 0)]\n",
    "VN = rel0y.loc[(rel0y['Comparador'] == 'Irrelevante')]\n",
    "\n",
    "#--------FALSO NEGATIVO--------\n",
    "rel1y = test.loc[(test['Relev√¢ncia'] == 1)]\n",
    "FN = rel1y.loc[(rel1y['Comparador'] == 'Irrelevante')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pVP = (len(VP)*100)/500\n",
    "print(\"PORCENTAGEM VERDADEIRO POSITIVO: {0}\".format(pVP))\n",
    "\n",
    "pFP = (len(FP)*100)/500\n",
    "print(\"PORCENTAGEM FALSO POSITIVO: {0}\".format(pFP))\n",
    "\n",
    "pVN = (len(VN)*100)/500\n",
    "print(\"PORCENTAGEM VERDADEIRO NEGATIVO: {0}\".format(pVN))\n",
    "\n",
    "pFN = (len(FN)*100)/500\n",
    "print(\"PORCENTAGEM FALSO NEGATIVO: {0}\".format(pFN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------ACURACIA EM PORCENTAGEM----\n",
    "acuP = ((len(VP)+len(VN))*100)/500\n",
    "print(\"ACUR√ÅCIA EM PORCENTAGEM: {0}\".format(acuP))\n",
    "#------ACURACIA EM VALORES--------\n",
    "acu = ((len(VP)+len(VN)))/500\n",
    "print(\"ACUR√ÅCIA: {0}\".format(acu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O comparador apresentou um desempenho razoavelmente bom, levando em conta que a porcentagem de classifica√ß√µes falsas est√° menor que 20%, sendo falsos positivos 0% e falsos negativos de 16.4%. Entretanto, esse valor ainda n√£o √© excelente para um classificador. Com isso, algumas coisas que podem ser feitas para melhorar seu desempenho s√£o aumentar a base de\n",
    "dados (pegar um numero maior de tweets) e aumentar a quantidades de classificadores, como por exemplo, adicionar uma \n",
    "classifica√ß√£o exclusiva para tweets que apresentam ironia e ou dupla nega√ß√£o (Na implementa√ß√£o desse classificador foi optado \n",
    "por direcionar esses tipos de tweets como relevantes). Posto isto, como o classificador apresentou uma porcentagem de acertos\n",
    "maior que 80% √© evidente que o projeto necessita de ajustes, por√©m, nada dr√°stico. Por fim, apos essa analise de dados e do \n",
    "desempenho do projeto √© valido que o investimento no projeto continue. Obrigada a todos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste\n",
    "\n",
    "Caso for fazer esse item do Projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Trabalhos que conseguirem pelo menos conceito B v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* IMPLEMENTOU outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o contida nos tweets. Ex: stemming, lemmatization, stopwords\n",
    "* CORRIGIU separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* CRIOU categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante. Pelo menos quatro categorias, com adi√ß√£o de mais tweets na base, conforme enunciado. (OBRIGAT√ìRIO PARA TRIOS, sem contar como item avan√ßado)\n",
    "* EXPLICOU porqu√™ n√£o pode usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* PROP√îS diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* SUGERIU e EXPLICOU melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* FEZ o item 6. Qualidade do Classificador a partir de novas separa√ß√µes dos tweets entre Treinamento e Teste descrito no enunciado do projeto (OBRIGAT√ìRIO para conceitos A ou A+)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
